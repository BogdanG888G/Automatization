import os
import logging
import pandas as pd
import pickle
from datetime import datetime
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from airflow import DAG
from airflow.operators.python import PythonOperator

def clean_text(text):
    if pd.isna(text) or not isinstance(text, str):
        return ""
    text = text.lower()
    import re
    text = re.sub(r'[¬´¬ª""‚Äú‚Äù]', '', text)
    text = re.sub(r'[.,;:/\-]', ' ', text)
    text = re.sub(r'\s+', ' ', text)
    return text.strip()

def train_region_by_city():
    INPUT_CSV = "ml_models/address_enrichment/labeled_region_data.csv"
    MODEL_PATH = "ml_models/address_enrichment/region_model.pkl"
    VECTORIZER_PATH = "ml_models/address_enrichment/region_vectorizer.pkl"

    logging.info(f"üìÇ –¢–µ–∫—É—â–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {os.getcwd()}")

    if not os.path.exists(INPUT_CSV):
        raise FileNotFoundError(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {INPUT_CSV}")

    df = pd.read_csv(INPUT_CSV, sep=';')
    df = df.drop_duplicates()

    # –£–±–∏—Ä–∞–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –ø—É—Å—Ç—ã–º–∏ –≥–æ—Ä–æ–¥–∞–º–∏ –∏–ª–∏ —Ä–µ–≥–∏–æ–Ω–∞–º–∏
    df.dropna(subset=['city', 'region'], inplace=True)

    logging.info(f"üìä –ö–æ–ª-–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤: {df['city'].nunique()}")
    logging.info(f"üìä –ö–æ–ª-–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤: {df['region'].nunique()}")

    # –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –≥–æ—Ä–æ–¥–∞
    df['cleaned_city'] = df['city'].apply(clean_text)

    # –£–¥–∞–ª—è–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –≥–æ—Ä–æ–¥–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø—É—Å—Ç—ã–µ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏)
    df = df[df['cleaned_city'].str.len() > 1]

    # –§–∏–ª—å—Ç—Ä—É–µ–º —Ä–µ–≥–∏–æ–Ω—ã —Å –º–∏–Ω–∏–º—É–º 2 –ø—Ä–∏–º–µ—Ä–∞–º–∏
    region_counts = df['region'].value_counts()
    valid_regions = region_counts[region_counts >= 2].index
    df = df[df['region'].isin(valid_regions)]

    if df.empty:
        raise ValueError("‚ùå –ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º —Å –º–∏–Ω–∏–º—É–º 2 –ø—Ä–∏–º–µ—Ä–∞–º–∏ –¥–∞—Ç–∞—Å–µ—Ç –ø—É—Å—Ç.")

    logging.info(f"üìä –ö–æ–ª-–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {df['region'].nunique()}")

    X = df['cleaned_city']
    y = df['region']

    vectorizer = TfidfVectorizer(
        ngram_range=(1, 3),
        max_features=20000,
        min_df=2,
        max_df=0.95
    )
    X_vec = vectorizer.fit_transform(X)

    X_train, X_test, y_train, y_test = train_test_split(
        X_vec, y, test_size=0.4, random_state=42, stratify=y
    )

    model = LogisticRegression(
        C=1.0,
        max_iter=2000,
        n_jobs=-1,
        random_state=42,
        verbose=1,
        class_weight='balanced'
    )
    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)
    logging.info("\nüìà –ö–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏ (—Ä–µ–≥–∏–æ–Ω –ø–æ –≥–æ—Ä–æ–¥—É):\n" + classification_report(y_test, y_pred, zero_division=0))

    os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)
    with open(MODEL_PATH, 'wb') as f_model:
        pickle.dump(model, f_model)
    with open(VECTORIZER_PATH, 'wb') as f_vec:
        pickle.dump(vectorizer, f_vec)

    logging.info(f"‚úÖ –ú–æ–¥–µ–ª—å —Ä–µ–≥–∏–æ–Ω–∞ –ø–æ –≥–æ—Ä–æ–¥—É —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {MODEL_PATH}")
    logging.info(f"‚úÖ –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {VECTORIZER_PATH}")

# DAG airflow
default_args = {
    'start_date': datetime(2023, 1, 1),
    'owner': 'airflow',
    'retries': 1,
}

with DAG(
    dag_id='train_region_by_city_model_dag',
    default_args=default_args,
    schedule_interval=None,
    max_active_runs=1,
    concurrency=1,
    catchup=False,
    tags=['model_training', 'region', 'city'],
    description='–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Ä–µ–≥–∏–æ–Ω–∞ –ø–æ –≥–æ—Ä–æ–¥—É',
) as dag:

    train_region_task = PythonOperator(
        task_id='train_region_by_city_model',
        python_callable=train_region_by_city,
    )

    train_region_task
