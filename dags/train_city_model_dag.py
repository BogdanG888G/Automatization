from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime
import pandas as pd
import pickle
import os
import re

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report


def clean_address(text):
    if pd.isna(text):
        return ""
    text = text.lower()

    # –£–¥–∞–ª—è–µ–º —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã
    text = re.sub(r'[¬´¬ª""‚Äú‚Äù]', '', text)
    text = re.sub(r'[.,;:/\-]', ' ', text)
    text = re.sub(r'\s+', ' ', text)

    # –£–±–∏—Ä–∞–µ–º "—à—É–º–æ–≤—ã–µ" —Å–ª–æ–≤–∞
    noise_words = [
        '—É–ª', '–¥–æ–º', '–∫–æ—Ä–ø—É—Å', '–∫–≤', '–æ—Ñ–∏—Å', '–ø–æ–º–µ—â', '—Å—Ç—Ä–æ–µ–Ω–∏–µ', '—Å—Ç—Ä',
        '–ø—Ä–æ–µ–∑–¥', '–ø—Ä', '–ø–µ—Ä', '–º–∫—Ä', '‚Ññ', '–∑–¥–∞–Ω–∏–µ', '–≤–ª–∞–¥–µ–Ω–∏–µ', '–∫', '–¥', '–≥',
        '–æ–±–ª', '—Ä-–Ω', '—Ä–ø', '—Å', '–ø', '–ø–≥—Ç', '–ê–û', '–ü', '/', 'H'  # –≥–µ–æ-—Å–æ–∫—Ä–∞—â–µ–Ω–∏—è
    ]
    for word in noise_words:
        text = re.sub(rf'\b{word}\b', '', text)

    return text.strip()


def train_city_model():
    # –ü—É—Ç–∏
    INPUT_CSV = "ml_models/address_enrichment/labeled_address_data.csv"
    MODEL_PATH = "ml_models/address_enrichment/city_model.pkl"
    VECTORIZER_PATH = "ml_models/address_enrichment/city_vectorizer.pkl"

    print(f"üìÇ –†–∞–±–æ—á–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {os.getcwd()}")

    if not os.path.exists(INPUT_CSV):
        raise FileNotFoundError(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {INPUT_CSV}")

    # –ó–∞–≥—Ä—É–∑–∫–∞
    df = pd.read_csv(INPUT_CSV, sep=';')
    print(f"üîç –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫: {len(df)}")

    # –û—á–∏—Å—Ç–∫–∞
    df.dropna(subset=['address', 'city'], inplace=True)
    df['cleaned_address'] = df['address'].apply(clean_address)
    df = df[df['cleaned_address'].str.len() > 5]

    # –£–¥–∞–ª—è–µ–º –≥–æ—Ä–æ–¥–∞, –∫–æ—Ç–æ—Ä—ã–µ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è < 2 —Ä–∞–∑
    city_counts = df['city'].value_counts()
    df = df[df['city'].isin(city_counts[city_counts >= 2].index)]

    if df.empty:
        raise ValueError("‚ùå –ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º –ø—É—Å—Ç.")

    print(f"üìä –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤: {df['city'].nunique()}")
    print(f"üèôÔ∏è –¢–æ–ø-10 –≥–æ—Ä–æ–¥–æ–≤:\n{df['city'].value_counts().head(10)}")

    # –û–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
    X = df['cleaned_address']
    y = df['city']

    # –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è
    vectorizer = TfidfVectorizer(
        ngram_range=(1, 3),
        max_features=20000,
        min_df=2,
        max_df=0.95
    )
    X_vec = vectorizer.fit_transform(X)

    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X_vec, y, test_size=0.2, random_state=42, stratify=y
    )

    # –ú–æ–¥–µ–ª—å
    model = LogisticRegression(
        C=1.0,
        max_iter=1000,
        n_jobs=-1,
        random_state=42,
        verbose=1
    )
    model.fit(X_train, y_train)

    # –û—Ü–µ–Ω–∫–∞
    y_pred = model.predict(X_test)
    print("üìà –ö–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏:\n")
    print(classification_report(y_test, y_pred, zero_division=0))

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)
    with open(MODEL_PATH, 'wb') as f_model:
        pickle.dump(model, f_model)
    with open(VECTORIZER_PATH, 'wb') as f_vec:
        pickle.dump(vectorizer, f_vec)

    print(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {MODEL_PATH}")
    print(f"‚úÖ –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {VECTORIZER_PATH}")


# –ê—Ä–≥—É–º–µ–Ω—Ç—ã DAG
default_args = {
    'start_date': datetime(2023, 1, 1),
    'owner': 'airflow',
    'retries': 1,
}

# DAG
with DAG(
    dag_id='train_city_model_dag',
    default_args=default_args,
    schedule_interval=None,
    catchup=False,
    tags=['model_training', 'address', 'city'],
    description='–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –≥–æ—Ä–æ–¥–∞ –∏–∑ –∞–¥—Ä–µ—Å–∞ (—Ç–æ–ª—å–∫–æ –ø–æ –ø–æ–ª—é address)',
) as dag:

    train_model_task = PythonOperator(
        task_id='train_city_model',
        python_callable=train_city_model,
    )

    train_model_task
