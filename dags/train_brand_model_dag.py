from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime
import os
import pandas as pd
import pickle
import re
import tempfile
import shutil

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

def clean_text(text):
    text = text.lower()
    text = re.sub(r'\d+[–≥–≥–º–ª—à—Ç–ª–∫]*', ' ', text)
    text = re.sub(r'[^a-z–∞-—è—ë\s]', ' ', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

def safe_save(obj, filepath):
    """–ù–∞–¥–µ–∂–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
    try:
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        with tempfile.NamedTemporaryFile(delete=False) as tmp_file:
            tmp_path = tmp_file.name
            pickle.dump(obj, tmp_file)
        
        # –°–æ–∑–¥–∞–µ–º —Ü–µ–ª–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
        os.makedirs(os.path.dirname(filepath), exist_ok=True, mode=0o755)
        
        # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –≤ —Ü–µ–ª–µ–≤–æ–µ —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ
        shutil.move(tmp_path, filepath)
        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {filepath}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ {filepath}: {str(e)}")
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª, –µ—Å–ª–∏ –æ–Ω –æ—Å—Ç–∞–ª—Å—è
        if os.path.exists(tmp_path):
            try:
                os.unlink(tmp_path)
            except:
                pass
        raise

def train_brand_model():
    # –ü—É—Ç–∏ (–æ—Å—Ç–∞–≤–ª—è–µ–º –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
    INPUT_CSV = "ml_models/product_enrichment/labeled_brand_products.csv"
    MODEL_PATH = "ml_models/product_enrichment/brand_model.pkl"
    VECTORIZER_PATH = "ml_models/product_enrichment/brand_vectorizer.pkl"

    if not os.path.exists(INPUT_CSV):
        raise FileNotFoundError(f"‚ùå CSV-—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {INPUT_CSV}")

    try:
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        df = pd.read_csv(INPUT_CSV, sep=';')
        df = df.drop_duplicates()
        df.dropna(subset=['product_name', 'brand'], inplace=True)
        df['product_name'] = df['product_name'].astype(str).apply(clean_text)
        df['brand'] = df['brand'].astype(str).str.title().str.strip()

        # –£–¥–∞–ª—è–µ–º —Ä–µ–¥–∫–∏–µ –±—Ä–µ–Ω–¥—ã
        brand_counts = df['brand'].value_counts()
        df = df[df['brand'].isin(brand_counts[brand_counts >= 2].index)]

        X = df['product_name']
        y = df['brand']

        # –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è
        vectorizer = TfidfVectorizer(
            ngram_range=(1, 4),
            max_features=30000,
            min_df=2,
            max_df=0.95,
            stop_words=['—à—Ç', '—É–ø', '–≥', '–≥—Ä', '–º–ª']
        )
        X_vec = vectorizer.fit_transform(X)

        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        X_train, X_test, y_train, y_test = train_test_split(
            X_vec, y, test_size=0.2, random_state=42, stratify=y
        )

        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        model = RandomForestClassifier(
            n_estimators=1000,
            class_weight='balanced',
            random_state=42,
            n_jobs=-1
        )
        model.fit(X_train, y_train)

        # –û—Ü–µ–Ω–∫–∞
        y_pred = model.predict(X_test)
        report = classification_report(y_test, y_pred)
        print("üìä –û—Ç—á–µ—Ç –ø–æ –º–µ—Ç—Ä–∏–∫–∞–º –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏:\n", report)

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –º–µ—Ç–æ–¥–∞
        safe_save(model, MODEL_PATH)
        safe_save(vectorizer, VECTORIZER_PATH)

        print(f"‚úÖ –ú–æ–¥–µ–ª—å –±—Ä–µ–Ω–¥–∞ –æ–±—É—á–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞:\n‚Üí {MODEL_PATH}\n‚Üí {VECTORIZER_PATH}")
    
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}")
        raise

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ DAG
default_args = {
    'owner': 'airflow',
    'start_date': datetime(2023, 1, 1),
    'retries': 1,  # –î–æ–±–∞–≤–ª—è–µ–º –æ–¥–Ω—É –ø–æ–ø—ã—Ç–∫—É –ø–æ–≤—Ç–æ—Ä–∞
}

with DAG(
    dag_id='train_brand_model',
    default_args=default_args,
    schedule_interval=None,
    catchup=False,
    tags=['model_training', 'brand'],
) as dag:

    train_brand_task = PythonOperator(
        task_id='train_brand_model_task',
        python_callable=train_brand_model
    )

    train_brand_task