from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime
import os
import pandas as pd
import pickle
import re

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report


def clean_text(text):
    text = text.lower()
    text = re.sub(r'\d+[–≥–≥–º–ª—à—Ç–ª–∫]*', ' ', text)
    text = re.sub(r'[^a-z–∞-—è—ë\s]', ' ', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text


def safe_save(obj, filepath):
    """–ù–∞–¥–µ–∂–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ —Å –∞—Ç–æ–º–∞—Ä–Ω–æ–π –∑–∞–º–µ–Ω–æ–π"""
    dir_path = os.path.dirname(filepath)
    os.makedirs(dir_path, exist_ok=True, mode=0o755)

    tmp_path = os.path.join(dir_path, f".tmp_{os.path.basename(filepath)}")
    try:
        with open(tmp_path, "wb") as tmp_file:
            pickle.dump(obj, tmp_file)

        # os.replace –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –∞—Ç–æ–º–∞—Ä–Ω—É—é –∑–∞–º–µ–Ω—É —Ñ–∞–π–ª–∞
        os.replace(tmp_path, filepath)
        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {filepath}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ {filepath}: {str(e)}")
        if os.path.exists(tmp_path):
            try:
                os.unlink(tmp_path)
            except:
                pass
        raise


def train_brand_model():
    INPUT_CSV = "ml_models/product_enrichment/labeled_brand_products.csv"
    MODEL_PATH = "ml_models/product_enrichment/brand_model.pkl"
    VECTORIZER_PATH = "ml_models/product_enrichment/brand_vectorizer.pkl"

    if not os.path.exists(INPUT_CSV):
        raise FileNotFoundError(f"‚ùå CSV-—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {INPUT_CSV}")

    try:
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        df = pd.read_csv(INPUT_CSV, sep=';').drop_duplicates()
        df.dropna(subset=['product_name', 'brand'], inplace=True)
        df['product_name'] = df['product_name'].astype(str).apply(clean_text)
        df['brand'] = df['brand'].astype(str).str.title().str.strip()

        # –£–¥–∞–ª—è–µ–º —Ä–µ–¥–∫–∏–µ –±—Ä–µ–Ω–¥—ã
        brand_counts = df['brand'].value_counts()
        df = df[df['brand'].isin(brand_counts[brand_counts >= 2].index)]

        X = df['product_name']
        y = df['brand']

        # –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è
        vectorizer = TfidfVectorizer(
            ngram_range=(1, 2),
            max_features=10000,
            min_df=2,
            max_df=0.95,
            stop_words=['—à—Ç', '—É–ø', '–≥', '–≥—Ä', '–º–ª']
        )
        X_vec = vectorizer.fit_transform(X)

        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        X_train, X_test, y_train, y_test = train_test_split(
            X_vec, y, test_size=0.2, random_state=42, stratify=y
        )

        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        model = RandomForestClassifier(
            n_estimators=1000,
            class_weight='balanced',
            random_state=42,
            n_jobs=-1
        )
        model.fit(X_train, y_train)

        # –û—Ü–µ–Ω–∫–∞
        y_pred = model.predict(X_test)
        report = classification_report(y_test, y_pred)
        print("üìä –û—Ç—á–µ—Ç –ø–æ –º–µ—Ç—Ä–∏–∫–∞–º –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏:\n", report)

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        safe_save(model, MODEL_PATH)
        safe_save(vectorizer, VECTORIZER_PATH)

        print(f"‚úÖ –ú–æ–¥–µ–ª—å –±—Ä–µ–Ω–¥–∞ –æ–±—É—á–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞:\n‚Üí {MODEL_PATH}\n‚Üí {VECTORIZER_PATH}")

    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}")
        raise


# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ DAG
default_args = {
    'owner': 'airflow',
    'start_date': datetime(2023, 1, 1),
    'retries': 1,
}

with DAG(
    dag_id='train_brand_model',
    default_args=default_args,
    schedule_interval=None,
    catchup=False,
    tags=['model_training', 'brand'],
) as dag:

    train_brand_task = PythonOperator(
        task_id='train_brand_model_task',
        python_callable=train_brand_model
    )

    train_brand_task
